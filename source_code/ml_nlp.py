# -*- coding: utf-8 -*-
"""ML_Intermediate_Submission1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Beq-xIFp0YXPMOG0Mg9ts9tl81AUPEaL
"""

import pandas as pd
    df = pd.read_csv('dataset.csv')
    df = df.drop(columns=['description'])
    df.head()

category = pd.get_dummies(df.lang)
    df_baru = pd.concat([df, category], axis=1)
    df_baru = df_baru.drop(columns='lang')
    df_baru

category = df_baru['categories'].values
    label = df_baru[['en', 'fr', 'es', 'de', 'pl']].values

from sklearn.model_selection import train_test_split
    category_latih, category_test, label_latih, label_test = train_test_split(category, label, test_size=0.2)

from tensorflow.keras.preprocessing.text import Tokenizer
    from tensorflow.keras.preprocessing.sequence import pad_sequences
     
    tokenizer = Tokenizer(num_words=5000, oov_token='x')
    tokenizer.fit_on_texts(category_latih) 
    tokenizer.fit_on_texts(category_test)
     
    sekuens_latih = tokenizer.texts_to_sequences(category_latih)
    sekuens_test = tokenizer.texts_to_sequences(category_test)
     
    padded_latih = pad_sequences(sekuens_latih) 
    padded_test = pad_sequences(sekuens_test)

import tensorflow as tf
    model = tf.keras.Sequential([
        tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
        tf.keras.layers.LSTM(64),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(5, activation='softmax')
    ])
    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

num_epochs = 30
    history = model.fit(padded_latih, label_latih, epochs=num_epochs, 
                        validation_data=(padded_test, label_test), verbose=2)